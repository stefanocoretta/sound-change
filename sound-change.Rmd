---
title: "Modelling push chains in sound change"
author: "Stefano Coretta"
date: \today
output:
  pdf_document:
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    citation_package: natbib
bibliography: linguistics.bib
biblio-style: unified.bst
indent: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(zipfR)
library(ggplot2)
theme_set(theme_bw())
library(dplyr)
```

# Simulation 1

The first simulation models the effects of an enrouching category affected by a bias on the category towards which the former is moving. In our case, the encrouching category is the the BAT vowel, while the other category is the BET vowel.

The following chunks define some functions that will be used to initialise a lexicon of words containing either a BAT or a BET vowel.

The function `createLexicon()` generates and empty lexicon of specified `size` and it assings the specified `frequency` distribution to the words.

```{r createLexicon}
createLexicon <- function(size, frequency, group.size) {

    word <- seq(1, size)
    vowel <- rep(c("BAT", "BET"), size)
    class <- sample(rep(1:(size/group.size), each = group.size))
#    class <- c(rbind(sample(1:(size/group.size)), sample(1:(size/group.size))))
    cloud <- list()

    lexicon <- list()

    for (i in 1:size) {
        lexicon[[i]] <- list(word[i], frequency[i], vowel[i], cloud, class[i])
    }

    return(lexicon)
}
```

The frequency distribution is produced by the following function, `zipfDistr()`. The distribution is a random sample from a Zipfian distribution (it uses the `zipfR` package).

```{r zipfDistr}
zipfDistr <- function(size) {
    zipf.model <- lnre("zm", alpha = 2/7, B = 0.1)
    zipf.sample <- rlnre(zipf.model, n = size)
    zipf.distr <- sort(as.numeric(as.character(zipf.sample)))
    return(zipf.distr)
}
```

We then need a function for generating values for the BAT and BET vowels in the lexicon. Since the main change affected the second formant (F1), the function will return F1 values (in Barks). The function takes a `target` value, it applies random noise and a `bias` (if specified; the default is `0`). A noise window of 0.5 (between -0.25 and 0.25) is used for the application of the production noise.

```{r produceFormants}
produceFormants <- function(target, bias = 0) {
    noise <- sample(seq(-0.2, 0.2, by = 0.1), 1)
    outcome <- target + noise + bias
    return(outcome)
}
```

The function `populateLexicon()` adds formant values to the lexical items in the lexicon, following a normal distribution. It follows the principles outlined in @pierrehumbert2001 and @wedel2007. The chosen standard values for F1 are 6.5 Barks for BAT and 5 for BET.

```{r populateLexicon}
populateLexicon <- function(lexicon, iterations, probs, bat.f1, bet.f1) {
    for (i in 1:iterations) {
        item <- sample(seq(1, length(lexicon)), 1, prob = probs)
        cloud.size <- length(lexicon[[item]][[4]])
        if (item %% 2 != 0) {
            if (cloud.size == 0) {
                lexicon[[item]][[4]][[1]] <- produceFormants(bat.f1)
            } else if (cloud.size == 1) {
                target <- lexicon[[item]][[4]][[1]]
                lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
            } else {
                target <- sample(unlist(lexicon[[item]][[4]]), 1)
                lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
            }
        } else {
            if (cloud.size == 0) {
                lexicon[[item]][[4]][[1]] <- produceFormants(bet.f1)
            } else if (cloud.size == 1) {
                target <- lexicon[[item]][[4]][[1]]
                lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
            } else {
                target <- sample(unlist(lexicon[[item]][[4]]), 1)
                lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
            }
        }
    }
    return(lexicon)
}
```

We can now populate a lexicon with exemplars for BAT and BET vowels.

```{r lexicon}
set.seed(4321)

lexicon.size <- 1000
frequency <- zipfDistr(lexicon.size)
group.size <- 10
lexicon <- createLexicon(lexicon.size, frequency, group.size)

iterations <- 50000
bat.f1 <- 6.5
bet.f1 <- 5.5
lexicon <- populateLexicon(lexicon, iterations, frequency, bat.f1, bet.f1)
source.lexicon <- lexicon
```

```{r groups}
groups <- list()

for (i in 1:(lexicon.size/group.size)) {
    groups[[i]] <- list(i, list())
}

for (i in 1:lexicon.size) {
    class <- lexicon[[i]][[5]]
    groups[[class]][[2]][[length(groups[[class]][[2]]) + 1]] <- i
}

change <- data.frame("word" = numeric(),
                     "time" = numeric(),
                     "frequency" = numeric(),
                     "f1" = numeric(),
                     "vowel" = character()
                     )
```

Now we can implement the vowel shift.

```{r vowel-shift}
iterations <- 100000
bias <- -0.3

for (iteration in 1:iterations) {
    word <- sample(1:lexicon.size, 1, prob = frequency)

    #### Produce the chosen word ####

    if (word %% 2 != 0) { # odd words have "BAT"

        #### The chosen word is a BAT word ####

        if (length(lexicon[[word]][[4]]) == 0) {
            lexicon[[word]][[4]] <- list(produceFormants(bat.f1, bias))
        } else {
            target <- sample(1:length(lexicon[[word]][[4]]), 1)
            outcome <- produceFormants(lexicon[[word]][[4]][[target]], bias)
            lexicon[[word]][[4]][[length(lexicon[[word]][[4]]) + 1]] <- outcome
        }

        #### Categorisation process ####

        class <- lexicon[[word]][[5]][[1]]
        pool <- NULL
        for (i in 1:group.size){
            other.word <- groups[[class]][[2]][[i]]
            if (other.word %% 2 == 0) {
                pool <- c(pool, unlist(lexicon[[other.word]][[4]]))
            }
        }
        if (length(pool) > 0) {# some words don't have exemplars
            if (outcome <= max(pool)) {
                encoding.prob <- lexicon[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups[[class]][[2]][[i]]
                        if (length(lexicon[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon[[other.word]][[4]]):1) {
                                if (lexicon[[other.word]][[4]][[j]] == outcome) {
                                    if (length(lexicon[[other.word]][[4]]) == 1) {
                                        lexicon[[other.word]][[4]] <- list()
                                    } else {
                                        lexicon[[other.word]][[4]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    } else {

        #### The chosen word is a BET word ####

        if (length(lexicon[[word]][[4]]) == 0) {
            lexicon[[word]][[4]] <- list(produceFormants(bet.f1))
        } else {
            target <- sample(1:length(lexicon[[word]][[4]]), 1)
            outcome <- produceFormants(lexicon[[word]][[4]][[target]])
            lexicon[[word]][[4]][[length(lexicon[[word]][[4]]) + 1]] <- outcome
        }

        #### Categorisation process ####

        class <- lexicon[[word]][[5]][[1]]
        pool <- NULL
        for (i in 1:group.size){
            other.word <- groups[[class]][[2]][[i]]
            if (other.word %% 2 != 0) {
                pool <- c(pool, unlist(lexicon[[other.word]][[4]]))
            }
        }
        if (length(pool) > 0) {# some words don't have exemplars
            if (outcome >= min(pool)) {
                encoding.prob <- lexicon[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups[[class]][[2]][[i]]
                        if (length(lexicon[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon[[other.word]][[4]]):1) {
                                if (lexicon[[other.word]][[4]][[j]] == outcome) {
                                    if (length(lexicon[[other.word]][[4]]) == 1) {
                                        lexicon[[other.word]][[4]] <- list()
                                    } else {
                                        lexicon[[other.word]][[4]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    if (iteration %% 1000 == 0) {
        now.frequency <- NULL
        f1.mean <- NULL
        for (word in 1:lexicon.size) {
            word.frequency <- lexicon[[word]][[2]]
            now.frequency <- c(now.frequency, word.frequency)
            word.f1.mean <- mean(unlist(lexicon[[word]][[4]]))
            f1.mean <- c(f1.mean, word.f1.mean)
        }
        vowelss <- rep(c("BAT", "BET"), lexicon.size/2)
        words <- seq(1, lexicon.size)
        time <- rep(iteration, lexicon.size)
        change.current <- data.frame("word" = words, time, "frequency" = now.frequency, "f1" = f1.mean, "vowel" = vowelss)
        change <- rbind(change, change.current)
    }
}
```


```{r plot-source, eval = FALSE}
bat.source <- NULL
for (i in seq(1, 1000, by = 2)) {
    bat.source <- c(bat.source, unlist(source.lexicon[[i]][[4]]))
}

bet.source <- NULL
for (i in seq(2, 1000, by = 2)) {
    bet.source <- c(bet.source, unlist(source.lexicon[[i]][[4]]))
}

vowels.source <- data.frame(
    f1 = c(bat.source, bet.source),
    vowel = c(rep("BAT", times = length(bet.source)), rep("BET", times = length(bat.source)))
)

ggplot(vowels.source, aes(f1, colour = vowel)) +
    geom_density() +
    xlim(2, 9)
```


```{r plot-final, eval = FALSE}
bat <- NULL
for (i in seq(1, 1000, by = 2)) {
    bat <- c(bat, unlist(lexicon[[i]][[4]]))
}

bet <- NULL
for (i in seq(2, 1000, by = 2)) {
    bet <- c(bet, unlist(lexicon[[i]][[4]]))
}

vowels <- data.frame(
    f1 = c(bat, bet),
    vowel = c(rep("BAT", times = length(bet)), rep("BET", times = length(bat)))
)

ggplot(vowels, aes(f1, colour = vowel)) +
    geom_density() +
    xlim(2, 9)
```

```{r vowel-plot, eval = FALSE}
ggplot(change, aes(time, f1, colour = vowel)) +
    geom_smooth(se = FALSE)
```

```{r freq-bin}
change <- mutate(change,
                 freq.bin = ifelse(frequency < max(frequency)/2,
                                   "low",
                                   "high"
                                   )
                 )
```

```{r freq-plot}
ggplot(change, aes(time, f1, colour = freq.bin)) +
    facet_grid(. ~ vowel) +
    geom_smooth(se = FALSE) +
    xlab("time (iterations)") +
    ylab("F1 (Barks)") +
    scale_colour_discrete(name = "Frequency bin")
```

There's seems to be an interaction between the noise proportion and the bias proportion. It seems that the noise proportion needs to be big enough, but the bias proportion should be bigger than the bigger noise proportion possible.

# Simulation 2

```{r createLexicon2}
createLexicon2 <- function(size, frequency, group.size) {

    word <- seq(1, size)
    vowel <- rep(c("BAT", "BET", "BIT"), size)
    class <- sample(rep(1:(size/group.size), each = group.size))
#    class <- c(rbind(sample(1:(size/group.size)), sample(1:(size/group.size))))
    cloud.f1 <- list()
    cloud.f2 <- list()
    lexicon <- list()

    for (i in 1:size) {
        lexicon[[i]] <- list(word[i], frequency[i], vowel[i], cloud.f1, cloud.f2, class[i])
    }

    return(lexicon)
}
```

```{r populateLexicon2}
populateLexicon2 <- function(lexicon, iterations, probs, bat.f1, bat.f2, bet.f1, bet.f2, bit.f1, bit.f2) {
    for (i in 1:iterations) {
        item <- sample(seq(1, length(lexicon)), 1, prob = probs)
        cloud.size <- length(lexicon[[item]][[4]])
        if (cloud.size == 0) {
            if (lexicon[[item]][[3]] == "BAT") {
                f1 <- bat.f1
                f2 <- bat.f2
            } else if (lexicon[[item]][[3]] == "BET") {
                f1 <- bet.f1
                f2 <- bet.f2
            } else {
                f1 <- bit.f1
                f2 <- bit.f2
            }
            lexicon[[item]][[4]][[1]] <- produceFormants(f1)
            lexicon[[item]][[5]][[1]] <- produceFormants(f2)
        } else if (cloud.size == 1) {
            target <- lexicon[[item]][[4]][[1]]
            lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
            target <- lexicon[[item]][[5]][[1]]
            lexicon[[item]][[5]][[cloud.size + 1]] <- produceFormants(target)
        } else {
            target <- sample(unlist(lexicon[[item]][[4]]), 1)
            lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
            target <- sample(unlist(lexicon[[item]][[5]]), 1)
            lexicon[[item]][[5]][[cloud.size + 1]] <- produceFormants(target)
        }
    }
    return(lexicon)
}
```

```{r lexicon2}
set.seed(4321)

lexicon.size = 1000
frequency <- zipfDistr(lexicon.size)
group.size <- 10
lexicon2 <- createLexicon2(lexicon.size, frequency, group.size)

iterations <- 50000
bat.f1 <- 6.5
bat.f2 <- 12.7
bet.f1 <- 5.5
bet.f2 <- 13
bit.f1 <- 4
bit.f2 <- 13.3
lexicon2 <- populateLexicon2(lexicon2, iterations, frequency, bat.f1, bat.f2, bet.f1, bet.f2, bit.f1, bit.f2)
source.lexicon2 <- lexicon2
```

```{r groups2}
groups2 <- list()

for (i in 1:(lexicon.size/group.size)) {
    groups2[[i]] <- list(i, list())
}

for (i in 1:lexicon.size) {
    class <- lexicon2[[i]][[6]]
    groups2[[class]][[2]][[length(groups2[[class]][[2]]) + 1]] <- i
}

change2 <- data.frame("word" = numeric(),
                     "time" = numeric(),
                     "frequency" = numeric(),
                     "f1" = numeric(),
                     "vowel" = character()
                     )
```

```{r vowel-shift2}
iterations <- 20000
f1.bias <- -0.5
f2.bias <- 0.05

for (iteration in 1:iterations) {
    word <- sample(1:lexicon.size, 1, prob = frequency)

    #### Produce the chosen word ####

    if (lexicon2[[word]][[3]] == "BAT") {

        #### The chosen word is a BAT word ####

        if (length(lexicon2[[word]][[4]]) == 0) {
            lexicon2[[word]][[4]] <- list(produceFormants(bat.f1, f1.bias))
            lexicon2[[word]][[5]] <- list(produceFormants(bat.f2, f2.bias))
        } else {
            target <- sample(1:length(lexicon2[[word]][[4]]), 1)
            outcome.f1 <- produceFormants(lexicon2[[word]][[4]][[target]], f1.bias)
            # if (outcome.f1 < 4) {
            #     outcome.f1 <- 4
            # } else if (outcome.f1 > 6.5) {
            #     outcome.f1 <- 6.5
            # }
            lexicon2[[word]][[4]][[length(lexicon2[[word]][[4]]) + 1]] <- outcome.f1
            target <- sample(1:length(lexicon2[[word]][[5]]), 1)
            outcome.f2 <- produceFormants(lexicon2[[word]][[5]][[target]], f2.bias)
            # if (outcome.f2 < 12) {
            #     outcome.f2 <- 12
            # } else if (outcome.f2 > 14) {
            #     outcome.f2 <- 14
            # }
            lexicon2[[word]][[5]][[length(lexicon2[[word]][[5]]) + 1]] <- outcome.f2
        }

        #### Categorisation process ####

        class <- lexicon2[[word]][[6]][[1]]
        pool.f1 <- NULL
        pool.f2 <- NULL
        for (i in 1:group.size){
            other.word <- groups2[[class]][[2]][[i]]
            if (lexicon2[[other.word]][[3]] != "BAT") {
                pool.f1 <- c(pool.f1, unlist(lexicon2[[other.word]][[4]]))
                pool.f2 <- c(pool.f2, unlist(lexicon2[[other.word]][[5]]))
            }
        }
        if (length(pool) > 0) {# some words don't have exemplars
            if ((outcome.f1 >= min(pool.f1) & outcome.f1 <= max(pool.f1)) & (outcome.f2 >= min(pool.f2) & outcome.f2 <= max(pool.f2))) {
                encoding.prob <- lexicon2[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups2[[class]][[2]][[i]]
                        if (length(lexicon2[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon2[[other.word]][[4]]):1) {
                                if (lexicon2[[other.word]][[4]][[j]] == outcome.f1 &
                                    lexicon2[[other.word]][[5]][[j]] == outcome.f2) {
                                    if (length(lexicon2[[other.word]][[4]]) == 1) {
                                        lexicon2[[other.word]][[4]] <- list()
                                        lexicon2[[other.word]][[5]] <- list()
                                    } else {
                                        lexicon2[[other.word]][[4]][[j]] <- NULL
                                        lexicon2[[other.word]][[5]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    } else if (lexicon2[[word]][[3]] == "BET") {

        #### The chosen word is a BET word ####

        if (length(lexicon2[[word]][[4]]) == 0) {
            lexicon2[[word]][[4]] <- list(produceFormants(bet.f1))
            lexicon2[[word]][[5]] <- list(produceFormants(bet.f2))
        } else {
            target <- sample(1:length(lexicon2[[word]][[4]]), 1)
            outcome.f1 <- produceFormants(lexicon2[[word]][[4]][[target]])
            # if (outcome.f1 < 4) {
            #     outcome.f1 <- 4
            # } else if (outcome.f1 > 6.5) {
            #     outcome.f1 <- 6.5
            # }
            lexicon2[[word]][[4]][[length(lexicon2[[word]][[4]]) + 1]] <- outcome.f1
            target <- sample(1:length(lexicon2[[word]][[5]]), 1)
            outcome.f2 <- produceFormants(lexicon2[[word]][[5]][[target]])
            # if (outcome.f2 < 12) {
            #     outcome.f2 <- 12
            # } else if (outcome.f2 > 14) {
            #     outcome.f2 <- 14
            # }
            lexicon2[[word]][[5]][[length(lexicon2[[word]][[5]]) + 1]] <- outcome.f2
        }

        #### Categorisation process ####

        class <- lexicon2[[word]][[6]][[1]]
        pool.f1 <- NULL
        pool.f2 <- NULL
        for (i in 1:group.size){
            other.word <- groups2[[class]][[2]][[i]]
            if (lexicon2[[other.word]][[3]] != "BET") {
                pool.f1 <- c(pool.f1, unlist(lexicon2[[other.word]][[4]]))
                pool.f2 <- c(pool.f2, unlist(lexicon2[[other.word]][[5]]))
            }
        }
        if (length(pool) > 0) {# some words don't have exemplars
            if ((outcome.f1 >= min(pool.f1) & outcome.f1 <= max(pool.f1)) & (outcome.f2 >= min(pool.f2) & outcome.f2 <= max(pool.f2))) {
                encoding.prob <- lexicon2[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups2[[class]][[2]][[i]]
                        if (length(lexicon2[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon2[[other.word]][[4]]):1) {
                                if (lexicon2[[other.word]][[4]][[j]] == outcome.f1 &
                                    lexicon2[[other.word]][[5]][[j]] == outcome.f2) {
                                    if (length(lexicon2[[other.word]][[4]]) == 1) {
                                        lexicon2[[other.word]][[4]] <- list()
                                        lexicon2[[other.word]][[5]] <- list()
                                    } else {
                                        lexicon2[[other.word]][[4]][[j]] <- NULL
                                        lexicon2[[other.word]][[5]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    } else {
        #### The chosen word is a BIT word ####

        if (length(lexicon2[[word]][[4]]) == 0) {
            lexicon2[[word]][[4]] <- list(produceFormants(bit.f1))
            lexicon2[[word]][[5]] <- list(produceFormants(bit.f2))
        } else {
            target <- sample(1:length(lexicon2[[word]][[4]]), 1)
            outcome.f1 <- produceFormants(lexicon2[[word]][[4]][[target]])
            # if (outcome.f1 < 4) {
            #     outcome.f1 <- 4
            # } else if (outcome.f1 > 6.5) {
            #     outcome.f1 <- 6.5
            # }
            lexicon2[[word]][[4]][[length(lexicon2[[word]][[4]]) + 1]] <- outcome.f1
            target <- sample(1:length(lexicon2[[word]][[5]]), 1)
            outcome.f2 <- produceFormants(lexicon2[[word]][[5]][[target]])
            # if (outcome.f2 < 12) {
            #     outcome.f2 <- 12
            # } else if (outcome.f2 > 14) {
            #     outcome.f2 <- 14
            # }
            lexicon2[[word]][[5]][[length(lexicon2[[word]][[5]]) + 1]] <- outcome.f2
        }

        #### Categorisation process ####

        class <- lexicon2[[word]][[6]][[1]]
        pool.f1 <- NULL
        pool.f2 <- NULL
        for (i in 1:group.size){
            other.word <- groups2[[class]][[2]][[i]]
            if (lexicon2[[other.word]][[3]] != "BIT") {
                pool.f1 <- c(pool.f1, unlist(lexicon2[[other.word]][[4]]))
                pool.f2 <- c(pool.f2, unlist(lexicon2[[other.word]][[5]]))
            }
        }
        if (length(pool) > 0) {# some words don't have exemplars
            if ((outcome.f1 >= min(pool.f1) & outcome.f1 <= max(pool.f1)) & (outcome.f2 >= min(pool.f2) & outcome.f2 <= max(pool.f2))) {
                encoding.prob <- lexicon2[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups2[[class]][[2]][[i]]
                        if (length(lexicon2[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon2[[other.word]][[4]]):1) {
                                if (lexicon2[[other.word]][[4]][[j]] == outcome.f1 &
                                    lexicon2[[other.word]][[5]][[j]] == outcome.f2) {
                                    if (length(lexicon2[[other.word]][[4]]) == 1) {
                                        lexicon2[[other.word]][[4]] <- list()
                                        lexicon2[[other.word]][[5]] <- list()
                                    } else {
                                        lexicon2[[other.word]][[4]][[j]] <- NULL
                                        lexicon2[[other.word]][[5]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    if (iteration %% 1000 == 0) {
        now.frequency <- NULL
        f1.mean <- NULL
        for (word in 1:lexicon.size) {
            word.frequency <- lexicon2[[word]][[2]]
            now.frequency <- c(now.frequency, word.frequency)
            word.f1.mean <- mean(unlist(lexicon2[[word]][[4]]))
            f1.mean <- c(f1.mean, word.f1.mean)
        }
        vowelss <- rep_len(c("BAT", "BET", "BIT"), lexicon.size)
        words <- seq(1, lexicon.size)
        time <- rep(iteration, lexicon.size)
        change.current <- data.frame("word" = words, time, "frequency" = now.frequency, "f1" = f1.mean, "vowel" = vowelss)
        change2 <- rbind(change2, change.current)
    }
}
```

```{r plot-source2, eval = FALSE}
bat.f1.source <- NULL
for (i in seq(1, 1000, by = 3)) {
    bat.f1.source <- c(bat.f1.source, unlist(source.lexicon2[[i]][[4]]))
}
bat.f2.source <- NULL
for (i in seq(1, 1000, by = 3)) {
    bat.f2.source <- c(bat.f2.source, unlist(source.lexicon2[[i]][[5]]))
}

bet.f1.source <- NULL
for (i in seq(2, 1000, by = 3)) {
    bet.f1.source <- c(bet.f1.source, unlist(source.lexicon2[[i]][[4]]))
}
bet.f2.source <- NULL
for (i in seq(2, 1000, by = 3)) {
    bet.f2.source <- c(bet.f2.source, unlist(source.lexicon2[[i]][[5]]))
}

bit.f1.source <- NULL
for (i in seq(3, 1000, by = 3)) {
    bit.f1.source <- c(bit.f1.source, unlist(source.lexicon2[[i]][[4]]))
}
bit.f2.source <- NULL
for (i in seq(3, 1000, by = 3)) {
    bit.f2.source <- c(bit.f2.source, unlist(source.lexicon2[[i]][[5]]))
}

vowels.source2 <- data.frame(
    f1 = c(bat.f1.source, bet.f1.source, bit.f1.source),
    f2 = c(bat.f2.source, bet.f2.source, bit.f2.source),
    vowel = c(rep("BAT", times = length(bat.f1.source)), rep("BET", times = length(bet.f1.source)), rep("BIT", times = length(bit.f1.source)))
)

ggplot(vowels.source2, aes(f2, f1, colour = vowel)) +
    geom_point(alpha = 0.5) +
    scale_x_reverse(position = "top") +
    scale_y_reverse(position = "right")

ggplot(vowels.source2, aes(f1, colour = vowel)) +
    geom_density()

ggplot(vowels.source2, aes(f2, colour = vowel)) +
    geom_density()
```

```{r plot-final2, eval = FALSE}
bat.f1.final <- NULL
for (i in seq(1, 1000, by = 3)) {
    bat.f1.final <- c(bat.f1.final, unlist(lexicon2[[i]][[4]]))
}
bat.f2.final <- NULL
for (i in seq(1, 1000, by = 3)) {
    bat.f2.final <- c(bat.f2.final, unlist(lexicon2[[i]][[5]]))
}

bet.f1.final <- NULL
for (i in seq(2, 1000, by = 3)) {
    bet.f1.final <- c(bet.f1.final, unlist(lexicon2[[i]][[4]]))
}
bet.f2.final <- NULL
for (i in seq(2, 1000, by = 3)) {
    bet.f2.final <- c(bet.f2.final, unlist(lexicon2[[i]][[5]]))
}

bit.f1.final <- NULL
for (i in seq(3, 1000, by = 3)) {
    bit.f1.final <- c(bit.f1.final, unlist(lexicon2[[i]][[4]]))
}
bit.f2.final <- NULL
for (i in seq(3, 1000, by = 3)) {
    bit.f2.final <- c(bit.f2.final, unlist(lexicon2[[i]][[5]]))
}

vowels.final2 <- data.frame(
    f1 = c(bat.f1.final, bet.f1.final, bit.f1.final),
    f2 = c(bat.f2.final, bet.f2.final, bit.f2.final),
    vowel = c(rep("BAT", times = length(bat.f1.final)), rep("BET", times = length(bet.f1.final)), rep("BIT", times = length(bit.f1.final)))
)

ggplot(vowels.final2, aes(f2, f1, colour = vowel)) +
    geom_point(alpha = 0.5) +
    scale_x_reverse(position = "top") +
    scale_y_reverse(position = "right")

ggplot(vowels.final2, aes(f1, colour = vowel)) +
    geom_density()

ggplot(vowels.final2, aes(f2, colour = vowel)) +
    geom_density()
```

```{r freq-bin-2}
change2 <- mutate(change2,
                 freq.bin = ifelse(frequency < max(frequency)/2,
                                   "low",
                                   "high"
                                   )
                 )
```

```{r freq-plot2}
ggplot(change2, aes(time, f1, colour = freq.bin)) +
    facet_grid(. ~ vowel) +
    geom_smooth(se = FALSE) +
    xlab("time (iterations)") +
    ylab("F1 (Barks)") +
    scale_colour_discrete(name = "Frequency bin")
```

# Simulation 3

This simulation is an extention of Simulation 1, which had only two vowel categories. In this simulation I will try to add a third vowel category.

```{r createLexicon3}
createLexicon3 <- function(size, frequency, group.size) {

    word <- seq(1, size)
    vowel <- rep(c("BAT", "BET", "BIT"), size)
    class <- sample(rep(1:(size/group.size), each = group.size))
#    class <- c(rbind(sample(1:(size/group.size)), sample(1:(size/group.size))))
    cloud.f1 <- list()
    lexicon <- list()

    for (i in 1:size) {
        lexicon[[i]] <- list(word[i], frequency[i], vowel[i], cloud.f1,
                             class[i]
                             )
    }

    return(lexicon)
}
```

```{r populateLexicon3}
populateLexicon3 <- function(lexicon, iterations, probs, bat.f1, bet.f1, bit.f1) {
    for (i in 1:iterations) {
        item <- sample(seq(1, length(lexicon)), 1, prob = probs)
        cloud.size <- length(lexicon[[item]][[4]])
        if (cloud.size == 0) {
            if (lexicon[[item]][[3]] == "BAT") {
                f1 <- bat.f1
            } else if (lexicon[[item]][[3]] == "BET") {
                f1 <- bet.f1
            } else {
                f1 <- bit.f1
            }
            lexicon[[item]][[4]][[1]] <- produceFormants(f1)
        } else if (cloud.size == 1) {
            target <- lexicon[[item]][[4]][[1]]
            lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
        } else {
            target <- sample(unlist(lexicon[[item]][[4]]), 1)
            lexicon[[item]][[4]][[cloud.size + 1]] <- produceFormants(target)
        }
    }
    return(lexicon)
}
```

```{r lexicon3}
set.seed(4321)

lexicon.size <- 1000
frequency <- zipfDistr(lexicon.size)
group.size <- 10
lexicon3 <- createLexicon3(lexicon.size, frequency, group.size)

iterations <- 50000
bat.f1 <- 6.5
bet.f1 <- 5.5
bit.f1 <- 4.5
lexicon3 <- populateLexicon3(lexicon3, iterations, frequency, bat.f1, bet.f1, bit.f1)
source.lexicon3 <- lexicon3
```

```{r groups3}
groups3 <- list()

for (i in 1:(lexicon.size/group.size)) {
    groups3[[i]] <- list(i, list())
}

for (i in 1:lexicon.size) {
    class <- lexicon3[[i]][[5]]
    groups3[[class]][[2]][[length(groups3[[class]][[2]]) + 1]] <- i
}

change3 <- data.frame("word" = numeric(),
                     "time" = numeric(),
                     "frequency" = numeric(),
                     "f1" = numeric(),
                     "vowel" = character()
                     )
```

```{r vowel-shift-3}
iterations <- 100000
bias <- -0.2

for (iteration in 1:iterations) {
    word <- sample(1:lexicon.size, 1, prob = frequency)

    #### Produce the chosen word ####

    if (lexicon3[[word]][[3]] == "BAT") {

        #### The chosen word is a BAT word ####

        if (length(lexicon3[[word]][[4]]) == 0) {
            lexicon3[[word]][[4]] <- list(produceFormants(bat.f1, bias))
        } else {
            target <- sample(1:length(lexicon3[[word]][[4]]), 1)
            outcome <- produceFormants(lexicon3[[word]][[4]][[target]], bias)
            lexicon3[[word]][[4]][[length(lexicon3[[word]][[4]]) + 1]] <- outcome
        }

        #### Categorisation process ####

        class <- lexicon3[[word]][[5]][[1]]
        pool.e <- NULL
        for (i in 1:group.size){
            other.word <- groups3[[class]][[2]][[i]]
            if (lexicon3[[other.word]][[3]] == "BET") {
                pool.e <- c(pool.e, unlist(lexicon3[[other.word]][[4]]))
            }
        }
        if (length(pool.e) > 0) {# some words don't have exemplars
            if (outcome <= max(pool.e)) {
                encoding.prob <- lexicon3[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups3[[class]][[2]][[i]]
                        if (length(lexicon3[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon3[[other.word]][[4]]):1) {
                                if (lexicon3[[other.word]][[4]][[j]] == outcome) {
                                    if (length(lexicon3[[other.word]][[4]]) == 1) {
                                        lexicon3[[other.word]][[4]] <- list()
                                    } else {
                                        lexicon3[[other.word]][[4]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    } else if (lexicon3[[word]][[3]] == "BET") {

        #### The chosen word is a BET word ####

        if (length(lexicon3[[word]][[4]]) == 0) {
            lexicon3[[word]][[4]] <- list(produceFormants(bet.f1))
        } else {
            target <- sample(1:length(lexicon3[[word]][[4]]), 1)
            outcome <- produceFormants(lexicon3[[word]][[4]][[target]])
            lexicon3[[word]][[4]][[length(lexicon3[[word]][[4]]) + 1]] <- outcome
        }

        #### Categorisation process ####

        class <- lexicon3[[word]][[5]][[1]]
        pool.a <- NULL
        pool.i <- NULL
        for (i in 1:group.size){
            other.word <- groups3[[class]][[2]][[i]]
            if (lexicon3[[other.word]][[3]] == "BAT") {
                pool.a <- c(pool.a, unlist(lexicon3[[other.word]][[4]]))
            } else if (lexicon3[[other.word]][[3]] == "BIT") {
                pool.i <- c(pool.i, unlist(lexicon3[[other.word]][[4]]))
            }
        }
        if (length(pool.a) > 0 & length(pool.i) > 0) {# some words don't have exemplars
            if (outcome >= min(pool.a) || outcome <= max(pool.i)) {
                encoding.prob <- lexicon3[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups3[[class]][[2]][[i]]
                        if (length(lexicon3[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon3[[other.word]][[4]]):1) {
                                if (lexicon3[[other.word]][[4]][[j]] == outcome) {
                                    if (length(lexicon3[[other.word]][[4]]) == 1) {
                                        lexicon3[[other.word]][[4]] <- list()
                                    } else {
                                        lexicon3[[other.word]][[4]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    } else {
        #### The chosen word is a BIT word ####

        if (length(lexicon3[[word]][[4]]) == 0) {
            lexicon3[[word]][[4]] <- list(produceFormants(bit.f1))
        } else {
            target <- sample(1:length(lexicon3[[word]][[4]]), 1)
            outcome <- produceFormants(lexicon3[[word]][[4]][[target]])
            lexicon3[[word]][[4]][[length(lexicon3[[word]][[4]]) + 1]] <- outcome
        }

        #### Categorisation process ####

        class <- lexicon3[[word]][[5]][[1]]
        pool.e <- NULL
        for (i in 1:group.size){
            other.word <- groups3[[class]][[2]][[i]]
            if (lexicon3[[other.word]][[3]] == "BET") {
                pool.e <- c(pool.e, unlist(lexicon3[[other.word]][[4]]))
            }
        }
        if (length(pool.e) > 0) {# some words don't have exemplars
            if (outcome >= min(pool.e)) {
                encoding.prob <- lexicon3[[word]][[2]] /
                                max(frequency)
                encode <- sample(c("yes", "no"),
                                 1,
                                 prob = c(encoding.prob,
                                          1 - encoding.prob
                                 )
                )

                #### Encoding function ####
                if (encode == "no") {
                    for (i in 1:group.size) {
                        other.word <- groups3[[class]][[2]][[i]]
                        if (length(lexicon3[[other.word]][[4]]) != 0) {
                            for (j in length(lexicon3[[other.word]][[4]]):1) {
                                if (lexicon3[[other.word]][[4]][[j]] == outcome) {
                                    if (length(lexicon3[[other.word]][[4]]) == 1) {
                                        lexicon3[[other.word]][[4]] <- list()
                                    } else {
                                        lexicon3[[other.word]][[4]][[j]] <- NULL
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    if (iteration %% 1000 == 0) {
        now.frequency <- NULL
        f1.mean <- NULL
        for (word in 1:lexicon.size) {
            word.frequency <- lexicon3[[word]][[2]]
            now.frequency <- c(now.frequency, word.frequency)
            word.f1.mean <- mean(unlist(lexicon3[[word]][[4]]))
            f1.mean <- c(f1.mean, word.f1.mean)
        }
        vowelss <- rep_len(c("BAT", "BET", "BIT"), lexicon.size)
        words <- seq(1, lexicon.size)
        time <- rep(iteration, lexicon.size)
        change.current <- data.frame("word" = words, time, "frequency" = now.frequency, "f1" = f1.mean, "vowel" = vowelss)
        change3 <- rbind(change3, change.current)
    }
}
```

```{r plot-source-3, eval = FALSE}
bat.source <- NULL
for (i in seq(1, 1000, by = 2)) {
    bat.source <- c(bat.source, unlist(source.lexicon[[i]][[4]]))
}

bet.source <- NULL
for (i in seq(2, 1000, by = 2)) {
    bet.source <- c(bet.source, unlist(source.lexicon[[i]][[4]]))
}

vowels.source <- data.frame(
    f1 = c(bat.source, bet.source),
    vowel = c(rep("BAT", times = length(bet.source)), rep("BET", times = length(bat.source)))
)

ggplot(vowels.source, aes(f1, colour = vowel)) +
    geom_density() +
    xlim(2, 9)
```


```{r plot-final-3, eval = FALSE}
bat <- NULL
for (i in seq(1, 1000, by = 2)) {
    bat <- c(bat, unlist(lexicon3[[i]][[4]]))
}

bet <- NULL
for (i in seq(2, 1000, by = 2)) {
    bet <- c(bet, unlist(lexicon3[[i]][[4]]))
}

bit <- NULL
for (i in seq(2, 1000, by = 2)) {
    bit <- c(bit, unlist(lexicon3[[i]][[4]]))
}

vowels <- data.frame(
    f1 = c(bat, bet, bit),
    vowel = c(rep("BAT", times = length(bat)), rep("BET", times = length(bet)), rep("BIT", times = length(bet)))
)

ggplot(vowels, aes(f1)) +
    geom_density() +
    xlim(2, 9) +
    facet_grid(. ~ vowel)
```

```{r vowel-plot, eval = FALSE}
ggplot(change3, aes(time, f1, colour = vowel)) +
    geom_smooth(se = FALSE)
```

```{r freq-bin}
change3 <- mutate(change3,
                 freq.bin = ifelse(frequency < max(frequency)/2,
                                   "low",
                                   "high"
                                   )
                 )
```

```{r freq-plot}
ggplot(change3, aes(time, f1, colour = freq.bin)) +
    facet_grid(. ~ vowel) +
    geom_smooth(se = FALSE) +
    xlab("time (iterations)") +
    ylab("F1 (Barks)") +
    scale_colour_discrete(name = "Frequency bin")
```
