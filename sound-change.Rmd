---
title: "Simulation of sound change"
author: "Stefano Coretta"
date: "05/07/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(zipfR)
library(tidyverse)
theme_set(theme_bw())
library(lme4)
library(effects)
library(itsadug)
```

# Functions

```{r produce-formants}
produce_formants <- function(target, bias = 0) {
    noise <- sample(seq(-0.2, 0.2, by = 0.05), 1)
    outcome <- target + noise + bias
    return(outcome)
}
```

```{r}
create_lexicon <- function(lexicon_size, vowels, group_size, formants) {
    lexicon <- tibble(
        word = 1:lexicon_size,
        vowel = rep(vowels, len = lexicon_size),
        class = sample(rep(1:(lexicon_size/group_size), each = group_size,
                           len = lexicon_size)),
        frequency = rep(1:lexicon_size, each = length(vowels), len = lexicon_size),
        f1 = rep(as.list(formants), len = lexicon_size)
    )
    
    return(lexicon)
}
```

```{r resample}
resample <- function(x) {
    if (length(x) == 1) {
        return(x)
    } else {
        sample(x, 1)
    }
}
```

```{r populate-lexicon}
populate_lexicon <- function(lexicon) {
    lexicon_size <- nrow(lexicon)
    lexicon_frequency <- lexicon$frequency
    lexicon_f1 <- lexicon$f1
    
    for (i in 1:50000) {
        word_id <- sample(1:lexicon_size, 1, prob = lexicon_frequency)
        target <- resample(unlist(lexicon_f1[[word_id]]))
        outcome <- produce_formants(target)
        lexicon_f1[[word_id]][[length(lexicon_f1[[word_id]]) + 1]] <- outcome
    }
    
    lexicon$f1 <- lexicon_f1
    return(lexicon)
}
```

```{r get-encode}
get_encode <- function(condition) {
    if (condition) {
        encoding_prob <- lexicon_frequency[word_id] /
            max(lexicon_frequency)
        
        encode <- sample(c(TRUE, FALSE), 1,
            prob = c(
                encoding_prob, 1 - encoding_prob
            )
        )
    } else {
        encode <- TRUE
    }
    
    return(encode)
}
```


```{r sound-shift}
sound_shift <- function(lexicon_size, vowels, group_size, formants, biased_vowel, bias, iterations, save_freq) {
    lexicon <- create_lexicon(lexicon_size, vowels, group_size, formants) %>%
        populate_lexicon()
    
    lexicon_size <- nrow(lexicon)
    lexicon_vowel <- lexicon[["vowel"]]
    lexicon_class <- lexicon[["class"]]
    lexicon_frequency <- lexicon[["frequency"]]
    lexicon_f1 <- lexicon[["f1"]]
    number_vowels <- length(vowels)
    
    new_lexicon_f1 <- tibble(init = 1:lexicon_size)
    
    environment(get_encode) <- environment()
    
    for (iteration in 1:iterations) {
        word_id <- sample(1:lexicon_size, 1, prob = lexicon_frequency)
        
        vowel <- lexicon_vowel[word_id]
        word_class <- lexicon_class[word_id]
        
        if (vowel == biased_vowel) {
            current_bias <- bias
        } else {
            current_bias <- 0
        }
        
        #### Produce the chosen word ####
        
        target <- resample(unlist(lexicon_f1[word_id]))
        outcome <- produce_formants(target, current_bias)
        
        if (vowel == vowels[1]) {
            pool_max <- suppressWarnings(max(unlist(
                lexicon_f1[which(lexicon_vowel[which(lexicon_class == word_class)] == vowels[2])]
            )))
            
            encode <- get_encode(outcome <= pool_max)
            
        } else if (vowel == vowels[2]) {
            if (length(vowels) == 2) {
                pool_min <- suppressWarnings(min(unlist(
                lexicon_f1[which(lexicon_vowel[which(lexicon_class == word_class)] == vowels[1])]
                    )
                ))
                
                encode <- get_encode(outcome >= pool_min)
                
            } else { # if length(vowels) == 3
                pool_min <- suppressWarnings(min(unlist(
                    lexicon_f1[which(lexicon_vowel[which(lexicon_class == word_class)] == vowels[1])]
                    )
                ))
                
                pool_max <- suppressWarnings(max(unlist(
                    lexicon_f1[which(lexicon_vowel[which(lexicon_class == word_class)] == vowels[3])]
                    )
                ))
                
                encode <- get_encode(outcome >= pool_min || outcome <= pool_max)
            }
        } else { # if vowel == vowel[3]
            pool_min <- suppressWarnings(min(unlist(
                lexicon_f1[which(lexicon_vowel[which(lexicon_class == word_class)] == vowels[1])]
                )
            ))
            
            encode <- get_encode(outcome >= pool_min)
        }
        
        #### Encode ####
        
        if (encode) {
            lexicon_f1[[word_id]][[length(lexicon_f1[[word_id]]) + 1]] <- outcome
        }
    
    
        if (iteration %% save_freq == 0) {
            column <- as.character(iteration)
            
            new_lexicon_f1 <- mutate(
                new_lexicon_f1,
                !!column := lexicon_f1
            )
            
        }
    }
    
    lexicon <- cbind(lexicon, new_lexicon_f1) %>%
        rename(`0` = f1) %>%
        select(-init) %>%
        gather(time, f1, matches("\\d")) %>%
        mutate(time = as.integer(time)) %>%
        group_by(time, word) %>%
        mutate(f1_mean = mean(unlist(f1))) %>%
        ungroup()

    
    return(lexicon)
}
```

# Two vowels, F1

```{r}
lexicon <- sound_shift(
    lexicon_size = 100,
    vowels = c("BART", "BAT"),
    group_size = 5,
    formants = c(6.5, 5.5),
    biased_vowel = "BART",
    bias = -0.3,
    iterations = 200000,
    save_freq = 10000
)
```

```{r}
lexicon <- lexicon %>%
    mutate(
        freq_bin = ifelse(
            frequency < max(frequency)/2,
            "low",
            "high"
        )
    )
```

```{r}
lexicon %>%
    ggplot(aes(time, f1_mean)) +
    geom_point(alpha = 0.5, size = 0.5) +
    geom_smooth(aes(colour = vowel))
```

```{r}
lexicon %>%
    ggplot(aes(time, f1_mean, colour = frequency, group = word)) +
    geom_line() +
    facet_grid(. ~ vowel)
```

```{r}
lexicon %>%
    ggplot(aes(time, f1_mean, colour = freq_bin, group = word)) +
    geom_line(alpha = 0.5) +
    facet_grid(. ~ vowel)
```

```{r}
lexicon %>%
    ggplot(aes(time, f1_mean, colour = freq_bin)) +
    geom_point(alpha = 0.5, size = 0.5) +
    geom_smooth(se = FALSE) +
    facet_grid(. ~ vowel)
```

